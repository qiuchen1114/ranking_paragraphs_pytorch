{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.datasets import snli_dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "\n",
    "# premise::hypothesis::label::premise_transitions::hypothesis_transitions\n",
    "train_loader = snli_dataset(train=True)\n",
    "val_loader = snli_dataset(dev=True)\n",
    "test_loader = snli_dataset(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {}\n",
    "f = open('./data/glove.6B.300d.txt', 'r')\n",
    "for line in f:\n",
    "    splitLine = line.split()\n",
    "    word = splitLine[0]\n",
    "    embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "    glove[word] = embedding\n",
    "    \n",
    "word_dict = {'p*a*d':0, 'u*n*k':1}\n",
    "word_list = ['p*a*d', 'u*n*k']\n",
    "for word in glove.keys():\n",
    "    word_dict[word] = len(word_list)\n",
    "    word_list.append(word)\n",
    "    \n",
    "np.save('./data/glove_dict.npy', np.array(list(glove.values())))\n",
    "np.save('./data/word_dict.npy', word_dict)\n",
    "np.save('./data/word_list.npy', word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "train_r = []\n",
    "for data in train_loader:\n",
    "    p = nltk.word_tokenize(data['premise'].lower())\n",
    "    h = nltk.word_tokenize(data['hypothesis'].lower())\n",
    "    l = 1 if data['label'] == 'neutral' or data['label'] == 'neutral' else\\\n",
    "        0 if data['label'] == 'contradiction' else None\n",
    "    \n",
    "    if l is None:\n",
    "        continue\n",
    "    \n",
    "    train_x.append([word_dict[w] if word_dict.get(w)!=None else 1 for w in p])\n",
    "    train_y.append([word_dict[w] if word_dict.get(w)!=None else 1 for w in h])\n",
    "    train_r.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = []\n",
    "val_y = []\n",
    "val_r = []\n",
    "for data in val_loader:\n",
    "    p = nltk.word_tokenize(data['premise'].lower())\n",
    "    h = nltk.word_tokenize(data['hypothesis'].lower())\n",
    "    l = 1 if data['label'] == 'neutral' or data['label'] == 'neutral' else\\\n",
    "        0 if data['label'] == 'contradiction' else None\n",
    "    \n",
    "    if l is None:\n",
    "        continue\n",
    "    \n",
    "    val_x.append([word_dict[w] if word_dict.get(w)!=None else 1 for w in p])\n",
    "    val_y.append([word_dict[w] if word_dict.get(w)!=None else 1 for w in h])\n",
    "    val_r.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "test_y = []\n",
    "test_r = []\n",
    "for data in test_loader:\n",
    "    p = nltk.word_tokenize(data['premise'].lower())\n",
    "    h = nltk.word_tokenize(data['hypothesis'].lower())\n",
    "    l = 1 if data['label'] == 'neutral' or data['label'] == 'neutral' else\\\n",
    "        0 if data['label'] == 'contradiction' else None\n",
    "    \n",
    "    if l is None:\n",
    "        continue\n",
    "    \n",
    "    test_x.append([word_dict[w] if word_dict.get(w)!=None else 1 for w in p])\n",
    "    test_y.append([word_dict[w] if word_dict.get(w)!=None else 1 for w in h])\n",
    "    test_r.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 62\n"
     ]
    }
   ],
   "source": [
    "max_x = 0\n",
    "for x in train_x+val_x+test_x:\n",
    "    if max_x < len(x):\n",
    "        max_x = len(x)\n",
    "        \n",
    "max_y = 0\n",
    "for y in train_y+val_y+test_y:\n",
    "    if max_y < len(y):\n",
    "        max_y = len(y)\n",
    "        \n",
    "print(max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for x, y, l in zip(train_x, train_y, train_r):\n",
    "    len_x = len(x)\n",
    "    len_y = len(y)\n",
    "    x = x + [0] * (max_x-len_x) if len_x < max_x else x\n",
    "    y = y + [0] * (max_y-len_y) if len_y < max_y else y\n",
    "    train_data.append([x,len_x,y,len_y,l])\n",
    "    \n",
    "val_data = []\n",
    "for x, y, l in zip(val_x, val_y, val_r):\n",
    "    len_x = len(x)\n",
    "    len_y = len(y)\n",
    "    x = x + [0] * (max_x-len_x) if len_x < max_x else x\n",
    "    y = y + [0] * (max_y-len_y) if len_y < max_y else y\n",
    "    val_data.append([x,len_x,y,len_y,l])\n",
    "    \n",
    "test_data = []\n",
    "for x, y, l in zip(test_x, test_y, test_r):\n",
    "    len_x = len(x)\n",
    "    len_y = len(y)\n",
    "    x = x + [0] * (max_x-len_x) if len_x < max_x else x\n",
    "    y = y + [0] * (max_y-len_y) if len_y < max_y else y\n",
    "    test_data.append([x,len_x,y,len_y,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/train.npy', train_data)\n",
    "np.save('./data/val.npy', val_data)\n",
    "np.save('./data/test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183187 182764\n"
     ]
    }
   ],
   "source": [
    "a=b=0\n",
    "for r in train_r:\n",
    "    if r==0:\n",
    "        a+=1\n",
    "    elif r==1:\n",
    "        b+=1\n",
    "print(a,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
